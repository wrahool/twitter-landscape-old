#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212)
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788)
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788) #0.04
#5
#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212)
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.05
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.058
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.1
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.16
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.02
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.024
#1
#L = temp, S = seasonal, A = after
56.10212 / (56.10212 + 1209.89788) #0.04
m2$fit
#7
#L = perm, S = other, A = after
1423.36294 / (1423.36294 + 3125.63706)
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294)
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294) #0.12
0.044/0.024
0.16/0.058
0.086 / 0.086
0.31/0.12
0.044/0.024
0.16/0.058
0.086 /0.048
0.31/0.12
o for s = seasonal
#temp: 0.044/0.024
0.044/0.024
0.16/0.058
0.086/0.048
0.31/0.12
load("~/../Google Drive/Annenberg UPenn/8 Spring 2018/STAT 501 - Nonparametric Methods and Log Linear Models/Rst501.RData")
lalive.tab
load("~/../Google Drive/Annenberg UPenn/8 Spring 2018/STAT 501 - Nonparametric Methods and Log Linear Models/Rst501.RData")
lalive.tab
mt = margin.table(lalive.tab, c(2,3,4))
dimnames(mt)
#1.2
loglin(mt, list(1, c(2,3)), eps = 0.0001)
1 - pchisq(920.8895, 3)
pchisq(920.8895, 3)
#1.3
loglin(mt, list(c(1,2), c(1,3), c(2,3)), eps = 0.0001)
dimnames(mt)
1 - pchisq(26.90355, 1)
#1.4
mt
#OR for seasonal
1266*2753/(773*1362) #3.31
#OR for other
2005*7112/(1354*4549) #2.31
dimnames(lalive.tab)
loglin(lalive.tab, list(c(1,3,4),c(2,3,4)), eps = 0.0001)
pchisq(711.9607, 4)
dimnames(lalive.tab)
ft = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001, fit = T)$fit
ft
61.81396*759.81396/(1204.18604 * 13.18604) #2.95
217.66384 * 2586.66384 / (1144.33616 * 166.33616) # 2.95
192.95100 * 1306.95100 / (1812.04900 * 47.04900) #2.95
1402.57120 * 6180.57120 / (3146.42880 * 931.42880) #2.95
#3.2
ft = loglin(lalive.tab, list(c(1,2,4), c(1,3,4), c(2,3,4)), eps = 0.0001, fit = T)$fit
ft
#L = temp, S = seasonal
62.09456 * 760.09456 / (1203.90544 * 12.90544) #3.03
#L = perm, S = seasonal
219.90544 * 2588.90544 / (1142.09456 * 164.09456) #3.03
#L = temp, S = other
192.76041 * 1306.76041 / (1812.23959 * 47.23959) #2.94
#L = perm, S = other
1400.23959 * 6178.23959 / (3148.76041 * 933.76041) #2.94
#look at bulk pg 119; questions 1.4, 2.1, 2.2
m1 = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001)
dimnames(lalive.tab)
#look at bulk pg 119; questions 1.4, 2.1, 2.2
m1 = loglin(lalive.tab, list(c(1,2), c(1,3,4), c(2,3,4)), eps = 0.0001)
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), eps = 0.0001)
#chi sq:
m1$lrt - m2$lrt #13.23
#df:
m1$df - m2$df #1
#p-value:
1 - pchisq(m1$lrt - m2$lrt, m1$df - m2$df) #0.00027
m1$lrt
m2$lrt
#chi sq:
m1$lrt - m2$lrt #13.23
#df:
m1$df - m2$df #1
m1$df
m2$df
#3.6
m2 = loglin(lalive.tab, list(c(1,2,3), c(1,3,4), c(2,3,4)), fit = T, eps = 0.0001)
m2$fit
#L = temp, S = seasonal
56.10212 * 754.10212 / (1209.89788 *  18.89788) #1.85
#L = perm, S = seasonal
221.63706 * 2590.63706 / (1140.36294 * 162.36294) #3.10
#L = temp, S = other
173.89788 * 1287.89788 / (1831.10212 * 66.10212) #1.85
#L = perm, S = other
1423.36294 * 6201.36294 / (3125.63706 * 910.63706) #3.10
m2
1-pchisq(0.4275453, 2)
#3.7
#1
#L = temp, S = seasonal, A = after
56.10212 / (56.10212 + 1209.89788) #0.044
m2$fit
#2
#L = temp, S = seasonal, A = before
18.89788 / (18.89788 + 754.10212) #0.024
#3
#L = perm, S = seasonal, A = after
221.63706 / ( 221.63706 + 1140.36294) #0.16
#4
#L = perm, S = seasonal, A = before
162.36294 / (162.36294 + 2590.63706) #0.058
#5
#L = temp, S = other, A = after
173.89788 / (173.89788 + 1831.10212) #0.086
#6
#L = temp, S = other, A = before
66.10212 / (66.10212 + 1287.89788) #0.048
#7
#L = perm, S = other, A = after
1423.36294 / (1423.36294 + 3125.63706) #0.31
#8
#L = perm, S = other, A = before
910.63706 / (910.63706 + 6201.36294) #0.12
s = seasonal
#temp: 0.044/0.024 = 1.8
#after:before ratio for s = seasonal
#temp: 0.044/0.024 = 1.8
#after:before ratio for s = other
#after:before ratio for s = other
#temp: 0.086/0.048 = 1.79
x <- c(3:6, 9:12, 15:18)
x
rand()
rand
sample(x, 1)
install.packages("mturkr")
install.packages("MTurkR")
install.packages("MTurkR-GUI")
library(MTurkR)
?RegisterHITType
install.packages("ineq")
library(ineq)
version
df = read.csv("../Google Drive/Annenberg UPenn/0 Dissertation Project/02_ComScoreData/01_IndiaData/03_Auxiliary/avg_dc_pr_full.csv", as.is = T)
head(df)
cor.test(df$avg.dc, df$avg.pr)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "spearman", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "kendall", continuity = F, conf.level = 0.95)
df = read.csv("../Google Drive/Annenberg UPenn/0 Dissertation Project/02_ComScoreData/01_IndiaData/03_Auxiliary/avg_dc_pr_full.csv", as.is = T)
cor.test(df$avg.dc, df$avg.pr, method = "pearson", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "spearman", continuity = F, conf.level = 0.95)
cor.test(df$avg.dc, df$avg.pr, method = "kendall", continuity = F, conf.level = 0.95)
library(RJSONIO)
tweetscores::posterior_samples
tweetscores::posterior_samples$alpha
tweetscores::posterior_samples$gamma
class(tweetscores::posterior_samples$gamma)
class(tweetscores::posterior_samples$alpha)
dim(tweetscores::posterior_samples$alpha)
tweetscores::posterior_samples$alpha[1,]
library(tweetscores)
sd(8, 10, 11, 12, 14)
stdev(8, 10, 11, 12, 14)
sd(c(8, 10, 11, 12, 14))
boxplot(c(8, 10, 11, 12, 14))
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + (p^i)*((1-p)^(100-i))
}
sum
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + ((p^i)*((1-p)^(100-i)))
}
sum
i = 51
p = 0.51
P^i
p^i
(p^51)*((1-p)^49)
?choose
p = 0.51
sum = 0
for(i in 51:100) {
sum = sum + (choose(100, i)*(p^i)*((1-p)^(100-i)))
}
sum
choose(5, 1)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(100, i)*(p^i)*((1-p)^(100-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(1000, i)*(p^i)*((1-p)^(100-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:1000) {
sum = sum + (choose(1000, i)*(p^i)*((1-p)^(1000-i)))
}
print(sum)
p = 0.51
sum = 0
for(i in 501:10000) {
sum = sum + (choose(10000, i)*(p^i)*((1-p)^(10000-i)))
}
print(sum)
version()
version
library(stringr)
str_locate_all(x, "ATAT")
x = "XYZATATATXYZ"
str_locate_all(x, "ATAT")
str_locate_all(x, "(?=ATAT)")
str_locate_all(x, "[AT]")
str_locate_all(x, "[ATAT]")
setwd("C:/Users/Subhayan/Documents/Work/twitter-landscape/")
library(tidyverse)
library(ggrepel)
elite_df = read.csv("data/weak_elite_ideologies.csv", as.is = T)
elites = elite_df$username
following_df = read.csv("landscape_paper/master_edge_list.csv")
names(following_df) = c("user", "following")
elite_following_df = following_df[following_df$following %in% elites,]
elite_following_df = elite_following_df[elite_following_df$user != "Tip",]
elite_following_df$user = as.character(elite_following_df$user)
elite_following_df$following = as.character(elite_following_df$following)
setwd("C:/Users/Subhayan/Documents/Work/twitter-landscape/")
library(tidyverse)
library(ggrepel)
elite_df = read.csv("data/weak_elite_ideologies.csv", as.is = T)
elites = elite_df$username
following_df = read.csv("../echo-chamber-exp//master_edge_list.csv")
setwd("C:/Users/Subhayan/Documents/Work/twitter-landscape/")
library(tidyverse)
library(ggrepel)
elite_df = read.csv("data/weak_elite_ideologies.csv", as.is = T)
elites = elite_df$username
following_df = read.csv("../echo-chamber-exp/landscape_paper/master_edge_list.csv")
names(following_df) = c("user", "following")
elite_following_df = following_df[following_df$following %in% elites,]
elite_following_df = elite_following_df[elite_following_df$user != "Tip",]
elite_following_df$user = as.character(elite_following_df$user)
elite_following_df$following = as.character(elite_following_df$following)
elite_classes = read.csv("data/elite_classification.csv", as.is = T)
head(elite_following_df)
head(elite_classes)
classes = c("hard news", "meme", "organization", "political pundit",
"political figure",  "brand", "media outlet", "public figure",
"sports", "entertainment")
elite_activity <- read_csv("data/elites_activity.csv")
all_class_info <- NULL
for(class in classes) {
class_elites <- elite_classes %>%
filter(sector1 == class | sector2 == class | sector3 == class) %>%
pull(handle)
n_elites <- length(class_elites)
unique_followers_class <- elite_following_df %>%
filter(following %in% class_elites) %>%
pull(user) %>%
unique() %>%
length()
class_activity <- elite_activity %>%
filter(handle %in% tolower(class_elites)) %>%
pull(numberoftweets) %>%
sum()
class_row <- c(class, n_elites, unique_followers_class, class_activity)
all_class_info <- rbind(class_row, all_class_info)
}
all_class_info <- data.frame(all_class_info, row.names = NULL)
names(all_class_info) <- c("genre", "elite_count", "unique_followers", "number_of_tweets")
all_class_info$genre = as.character(all_class_info$genre)
all_class_info$elite_count = as.numeric(as.character(all_class_info$elite_count))
all_class_info$unique_followers = as.numeric(as.character(all_class_info$unique_followers))
all_class_info$number_of_tweets = as.numeric(as.character(all_class_info$number_of_tweets))
all_class_info$unique_followers_per_elite = all_class_info$unique_followers / all_class_info$elite_count
all_class_info$number_of_tweets_per_elite = all_class_info$number_of_tweets / all_class_info$elite_count
all_class_info_bkup <- all_class_info
all_class_info_bkup$number_of_tweets_scaled <- all_class_info_bkup$number_of_tweets/10000
all_class_info_bkup
all_class_info_long <- all_class_info_bkup %>%
select(-c(unique_followers_per_elite, number_of_tweets_per_elite)) %>%
gather(key, value, c(elite_count, unique_followers, number_of_tweets_scaled))
ggplot(all_class_info_long, aes(fill=key, y=value, x=genre)) +
geom_bar(position="dodge", stat="identity")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme_bw() +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
theme_bw()
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(aes(size=all_class_info$elite_count, colour = "red")) +
scale_size_continuous(range = c(4, 16.4)) +
theme_bw() +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(shapre = 21, aes(size=all_class_info$elite_count, fill = "red", color = "black")) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme_bw() +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(shape = 21, aes(size=all_class_info$elite_count, fill = "red", color = "black")) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme_bw() +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(shape = 21, color = "black", fill = "salmon", aes(size=all_class_info$elite_count)) +
scale_size_continuous(range = c(4, 16.4)) +
geom_text_repel(aes(label = all_class_info$genre),
size = 4) +
theme_bw() +
theme(legend.position="none")
ggplot(all_class_info, aes(x=unique_followers, y=number_of_tweets)) +
geom_point(shape = 21, color = "black", fill = "salmon", aes(size=all_class_info$elite_count)) +
scale_size_continuous(range = c(4, 16.4)) +
theme_bw() +
theme(legend.position="none")
#wt anlaysis
library(ggplot2)
library(plyr)
library(dplyr)
library(gridExtra)
library(moments)
setwd("C:/Users/Subhayan/Documents/Work/twitter-landscape/")
elite_df = read.csv("data/weak_elite_ideologies.csv", as.is = T)
elite_df[is.na(elite_df$ideology),]$ideology = 0
elite_df[elite_df$ideology == -Inf,]$ideology = -3
elite_df[elite_df$ideology == Inf,]$ideology = 3
names(elite_df)[2] = "ideology"
elite_freq = read.csv("data/elites_activity.csv", as.is = T)
names(elite_freq)[1] = "username"
elite_freq$numberoftweets_scaled = (elite_freq$numberoftweets - min(elite_freq$numberoftweets))/(max(elite_freq$numberoftweets) - min(elite_freq$numberoftweets))
elite_df$username = tolower(elite_df$username)
elite_freq_df = merge(elite_df, elite_freq)
elite_freq_df$corrected_ideology = elite_freq_df$ideology * elite_freq_df$numberoftweets_scaled
elite_followers_count = read.csv("data/elite_followers_count.csv")
load("data/walktrap_results.Rdata")
comm_membership <- data.frame(cbind(wt$names, wt$membership))
names(comm_membership) <- c("username", "community")
comm_membership$username <- tolower(as.character(comm_membership$username))
library(tidyverse)
elite_master_tbl <- elite_freq_df %>%
inner_join(comm_membership) %>%
inner_join(elite_followers_count)
mu1 <- ddply(elite_master_tbl, "community", summarise, grp.mean=mean(ideology, na.rm = T))
sd1 <- ddply(elite_master_tbl, "community", summarise, grp.sd=sd(ideology, na.rm = T))
mu2 <- ddply(elite_master_tbl, "community", summarise, grp.mean=mean(corrected_ideology, na.rm = T))
sd2 <- ddply(elite_master_tbl, "community", summarise, grp.sd=sd(corrected_ideology, na.rm = T))
elite_master_tbl %>%
select(community, ideology) %>%
group_by(community) %>%
mutate(mean_id = mean(ideology)) -> c_ideology_with_mu
p1 <- ggplot(c_ideology_with_mu, aes(ideology)) +
geom_density(fill = "snow3", alpha = 0.6, colour="black") +
facet_wrap(~community, nrow = 5, scales = "free") +
xlim(-3, 3) +
geom_vline(aes(xintercept=mean_id), colour = "red") +
geom_vline(xintercept=0, linetype = "dashed") +
theme(
strip.background = element_blank(),
strip.text.x = element_blank()
) +
theme(legend.position = "none") +
theme_bw()
elite_master_tbl %>%
select(community, corrected_ideology) %>%
group_by(community) %>%
mutate(mean_id = mean(corrected_ideology)) -> c_corrected_ideology_with_mu
p2 = ggplot(c_corrected_ideology_with_mu, aes(corrected_ideology)) +
geom_density(fill = "snow3", alpha = 0.6, colour="black") +
facet_wrap(~community, nrow = 5, scales = "free") +
xlim(-3, 3) +
geom_vline(aes(xintercept=mean_id), color = "red") +
geom_vline(xintercept=0, linetype = "dashed") +
theme(
strip.background = element_blank(),
strip.text.x = element_blank()
) +
theme(legend.position = "none") +
theme_bw()
# figure 7
grid.arrange(p1, p2, nrow = 1)
comm_stats <- NULL
for(c in 1:max(wt$membership)) {
c_ideologies <- elite_master_tbl %>%
filter(community %in% c) %>%
pull(ideology)
c_corrected_ideologies <- elite_master_tbl %>%
filter(community %in% c) %>%
pull(corrected_ideology)
c_tweetcount <- elite_master_tbl %>%
filter(community %in% c) %>%
pull(numberoftweets)
c_followers <- elite_master_tbl %>%
filter(community %in% c) %>%
pull(followers)
c_elite_count <- elite_master_tbl %>%
filter(community %in% c) %>%
pull(username)
c_i_mean = mean(c_ideologies)
c_i_sd = sd(c_ideologies)
c_i_median = median(c_ideologies)
c_i_skewness = skewness(c_ideologies)
c_i_kurtosis = kurtosis(c_ideologies)
c_ci_mean = mean(c_corrected_ideologies)
c_ci_sd = sd(c_corrected_ideologies)
c_ci_median = median(c_corrected_ideologies)
c_ci_skewness = skewness(c_corrected_ideologies)
c_ci_kurtosis = kurtosis(c_corrected_ideologies)
total_tweets = sum(c_tweetcount)
total_followers = sum(c_followers)
elite_count = length(c_elite_count)
c_row = c(c,
c_i_mean, c_i_sd, c_i_median, c_i_skewness, c_i_kurtosis,
c_ci_mean, c_ci_sd, c_ci_median, c_ci_skewness, c_ci_kurtosis,
total_tweets, total_followers, elite_count)
comm_stats <- rbind(comm_stats, c_row)
}
comm_stats <- data.frame(comm_stats, row.names = NULL)
names(comm_stats) = c("community",
"mean_id", "sd_id", "median_id", "skewness_id", "kurtosis_id",
"mean_cid", "sd_cid", "median_cid", "skewness_cid", "kurtosis_cid",
"total_tweets", "total_followers", "elite_count")
library(ggrepel)
#figure 8
ggplot(comm_stats, aes(x=total_followers, y=total_tweets)) +
geom_point(color = "black", shape = 21, aes(fill = comm_stats$median_id,size=comm_stats$elite_count)) +
geom_text_repel(aes(label = comm_stats$community),
size = 4) +
scale_size_continuous(range = c(4, 11.4)) +
scale_fill_gradient(low = "white", high = "salmon") +
theme_bw() +
theme(legend.position="none")
ggplot(comm_stats, aes(x=total_followers, y=total_tweets)) +
geom_point(color = "black", shape = 21, aes(fill = comm_stats$median_id,size=comm_stats$elite_count)) +
scale_size_continuous(range = c(4, 11.4)) +
scale_fill_gradient(low = "white", high = "salmon") +
theme_bw() +
theme(legend.position="none")
comm_stats
